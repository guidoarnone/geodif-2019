\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}
\usepackage{mathpazo}
\usepackage{euler}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{arrows}
\usetikzlibrary{matrix}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{enumitem}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Ss}{\mathbb{S}}
\newcommand{\M}[2]{\mathsf{M}_{#1}#2}
\newcommand{\im}{\operatorname{im}}
\newcommand{\eps}{\varepsilon}
\newcommand{\dpart}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\nat}[1]{[\![#1]\!]}
\newcommand{\natzero}[1]{\nat{#1}_0}
\newcommand{\adj}[1]{\operatorname{adj}(#1)}
\newcommand{\ip}[2]{\langle #1 , #2 \rangle}
\newcommand{\ol}{\overline}
\newcommand{\hook}[3]{\frac{\partial}{\partial x_{#1}}\Big\rvert_{#2}^{#3}}
\usepackage{rotating}
\newcommand*{\isoarrow}[1]{\arrow[#1,"\rotatebox{90}{\LARGE{\(\sim\)}}"
]}
\definecolor{color}{RGB}{155, 132, 0}
\newcommand{\paint}[1]{\color{color}{#1}}

\renewcommand*{\proofname}{\paint{Demostraci\'on}}
\newenvironment{theorem}[2][Teorema]{\begin{trivlist}
\item[\hskip \labelsep \paint{{\bfseries #1}}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lema]{\begin{trivlist}
\item[\hskip \labelsep \paint{{\bfseries #1}}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Ejercicio]{\begin{trivlist}
\item[\hskip \labelsep \paint{{\bfseries #1}}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{obs}[2][Observaci\'on]{\begin{trivlist}
\item[\hskip \labelsep \paint{{\bfseries #1.}}]}{\end{trivlist}}
\newenvironment{reflection}[2][Resoluci\']{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposici\'on]{\begin{trivlist}
\item[\hskip \labelsep \paint{{\bfseries #1}}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corolario]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

%-----------------------

\title{
\LARGE{\paint{Geometr\'ia Diferencial}}
\\
\vspace{0.5pt}
\small{\paint{Ejercicios para Entregar - Pr\'actica 3}}
}
\author{\paint{Guido Arnone}}
\date{}
\lhead{Guido Arnone}
\rhead{Pr\'actica 3}

\begin{document}

\maketitle

\begin{center}
\paint{\large{Sobre los Ejercicios}}
\end{center}
\begin{center}
Eleg\'i resolver los ejercicios $\paint{(2)}$, $\paint{(8)}$ y $\paint{(9)}$.
\end{center}
\begin{center}
$\paint{
\rule{400pt}{0.5pt}
}$
\vspace{35pt}
\end{center}

Recuerdo primero el siguiente resultado,

\begin{obs}{1} Si $M$ es una variedad diferenciable y $v \in T_pM$ una derivaci\'on en un punto $p \in M$, entonces para cada entorno abierto $U$ de $p$ existe una curva suave $c : (-\eps,\eps) \to M$ tal que $c(0) = p$, $c'(0) = v$, e $\im c \subset U$.

Consideremos primero una carta $(V,\phi)$ con $p \in V \subset U$. Componiendo con una traslaci\'on (que es un difeomorfismo de $\R^n$) si es necesario, podemos suponer que $\phi(p) = 0$. Ahora, como los \emph{ganchos} de $\phi$ en $p$ son una base para $T_pM$, existen \'unicos coeficientes $a_1, \dots, a_n \in \R$ tales que $v =\sum_{i=1}^na_i \frac{\partial}{\partial\phi^i}|_p$. 

Tomando $\eps > 0$ suficientemente peque\~{n}o como para que $B_\eps(0) \subset \phi(V)$, afirmamos que la curva
\begin{align*}
c : t \in (-\eps,\eps) \mapsto \phi^{-1}(t(a_1,\dots,a_n)) \in M
\end{align*} cumple lo pedido.

En primer lugar, tenemos que $c(0) = \phi^{-1}(0) = p$ e $\im c \subset V \subset U$. Observemos tambi\'en que $c$ es suave, pues es la composici\'on de la curva $\gamma : t \in \R \mapsto t(a_1,\dots,a_n) \in \R^n$ con $\phi^{-1}$ (que es suave ya que $\phi$ es una carta de $M$). 

Por \'ultimo si $g \in C^\infty(M)$, entonces
\begin{align*}
d_0c\left(\frac{d}{dt}\Big|_0\right)(g) &= \frac{d}{dt}\Big|_0(gc) = \frac{d}{dt}\Big|_0(g\phi^{-1}\gamma) = \sum_{i=1}^n\frac{\partial g\phi^{-1}}{\partial x_i}\Big|_{c(0)} \cdot \gamma'_i(0)\\
&= \sum_{i=1}^n\frac{\partial g\phi^{-1}}{\partial x_i}\Big|_{p} \cdot a_i = \sum_{i=1}^na_i\frac{\partial }{\partial \phi^i}\Big|_{p}(g)\\
&= \left(\sum_{i=1}^na_i\frac{\partial }{\partial \phi^i}\Big|_{p}\right)(g) = v(g)
\end{align*}
de forma que $c'(0) = v$.
\end{obs}
\newpage

\begin{exercise}{2} Sean $M$ una variedad y $f\in C^\infty(M)$. Si $f$ tiene un m\'aximo
local en $p\in M$, entonces $d_pf = 0$.
\end{exercise}
\begin{proof} Como $p$ es un m\'aximo local de $f$, existe un abierto $U \ni p$ tal que $f(q) \leq f(p)$ para cada $q \in U$. Fijemos $v \in T_pM$. Por la observaci\'on anterior tenemos una curva $c : (-\eps,\eps) \to M$ tal que $c(0) = p$, $c'(0) = v$, e $\im c \subset U$. 

En consecuencia, es $fc(t) \leq fc(0) = f(p)$ para cada $t \in (-\eps,\eps)$ y por lo tanto $0$ resulta un m\'aximo local de la curva suave $fc : (-\eps,\eps) \to \R$.

Esto último dice que $(fc)'(0) = 0$ y por ende es
\begin{align*}
0 = d_0(f\circ c)\left(\frac{d}{dt}\Big|_0\right)  = d_pf\left(d_0c\left(\frac{d}{dt}\Big|_0\right)\right) = d_pf(c'(0)) = d_pf(v).
\end{align*}
Como la igualdad anterior es cierta para cualquier $p \in M$ y $v \in T_pM$, efectivamente  $d_pf = 0$.
\end{proof}

\begin{center}
$\paint{
\rule{400pt}{0.5pt}
}$
\vspace{10pt}
\end{center}

Probamos ahora la sugerencia del ejercicio $\paint{(8)}$.

\begin{proposition}{2} Sea $G$ un grupo de Lie, $\mathfrak{g}$ su \'algebra de Lie y $X \in \mathfrak{g}$ un campo vectorial invariante a izquierda. Si $g, h \in G$ y $\gamma : (a,b) \to G$ es una curva integral de $X$ que arranca en $g = \gamma(0)$ entonces la curva $\eta : t \in (a,b) \to h\gamma(t) \in G$ es una curva integral de $X$ que arranca en $hg$. 
\end{proposition}
\begin{proof} Como $\eta(0) = h\gamma(0) = hg$, la curva $\eta$ comienza en $hg$. Resta ver que es una curva integral. Fijando $s \in (a,b)$ y notando que por definición $\eta = L_h \circ \gamma$, se tiene que
\begin{align*}
d_s \eta \left(\frac{d}{dt}\Bigg|_{s}\right) &= (d_{\gamma(s)}L_h \circ d_s\gamma) \left(\frac{d}{dt}\Bigg|_{s}\right) = d_{\gamma(s)}L_h \left( d_s\gamma \left(\frac{d}{dt}\Bigg|_{s}\right) \right)\\
& = d_{\gamma(s)}L_h(X_{\gamma(s)}) = X_{h\gamma(s)} = X_{\eta(s)}.
\end{align*}
Esto es precisamente que $\eta$ sea integral.
\end{proof}

\begin{exercise}{8} Sea $G$ un grupo de Lie, $\mathfrak{g}$ su álgebra de Lie y $X\in\mathfrak{g}$ un campo vectorial invariante a izquierda. Pruebe que $X$ es \emph{completo} y describa el flujo asociado.
\end{exercise}
\begin{proof} Veamos primero que existe una curva integral definida en toda la recta que comienza en la identidad de $G$. Consideremos la curva integral maximal $\gamma : (a,b) \to G$ que satisface $\gamma(0) = e$. 

Para concluir que $I := (a,b)$ es en realidad toda la recta, supongamos que $b < +\infty$ y veamos que esto lleva a una contradicción. Veremos así que $I$ no puede estar acotado superiormente. Un argumento similar para $a$ (que omitimos) prueba que $I$ tampoco está acotado inferiormente: en consecuencia, debe ser $I = \R$.

Fijemos $t_0 \in (0,b)$. Ahora, definimos
\begin{align*}
\eta  : (a-t_0,&b-t_0) \to G\\
&t \longmapsto \gamma(t+t_0)
\end{align*}
que resulta suave pues es la composición de $\gamma$ con la restricción de la traslación $T_{t_0}(t) = t + t_0$. Ésta curva es integral, pues
\begin{align*}
\eta'(s) = d_s\eta\left(\frac{d}{dt}\Big|_{s}\right) &= d_s(\gamma \circ T_{t_0})\left(\frac{d}{dt}\Big|_{s}\right) = d_{s+t_0}\gamma \circ d_{s}T_{t_0}\left(\frac{d}{dt}\Big|_s\right)\\
&= d_{s+t_0}\gamma\left(\frac{d}{dt}\Big|_{s+t_0}\right) = \gamma'(s+t_0) = X_{\gamma(s+t_0)} = X_{\eta(s)}.
\end{align*}


Ahora, tanto $\eta$ como $t \in (a,b) \mapsto \gamma(t_0)\gamma(t) \in G$ son curvas integrales que comienzan en $\gamma(t_0)$, así que deben coincidir donde ambas están definidas:
\begin{align*}
\gamma(s+t_0) = \eta(s) = \gamma(t_0)\gamma(s) \quad \forall s \in (a,b-t_0).
\end{align*}
En particular, si $x \in (t_0,b)$ es $\gamma(x) = \gamma(t_0)\gamma(x-t_0)$. Esto implica que la curva
\begin{align*}
\tilde{\gamma} : (a,b+&t_0) \to G\\
&s \longmapsto \begin{cases}
\gamma(s) \quad \text{ si $a < s < b$}\\
\gamma(t_0)\gamma(s-t_0) \quad \text{ si $t_0 < s < b + t_0$}
\end{cases}
\end{align*}
que comienza en $e \in G$ est\'a bien definida. M\'as a\'un, ésta resulta suave e integral pues lo es al restringirla a los abiertos $(a,b)$ y $(t_0,b+t_0)$. Sin embargo $\gamma$ era maximal, así que esto supone una contradicción. Por lo observado anteriormente, la curva $\gamma$ está definida en toda la recta.

Consecuentemente $X$ es completo: para cada $g \in G$, la $\paint{\text{Proposición $2$}}$ nos dice que la curva $g\cdot\gamma$ comienza en $g$, es integral, y está definida en toda la recta.
\end{proof}

\begin{center}
$\paint{
\rule{400pt}{0.5pt}
}$
\vspace{10pt}
\end{center}

\begin{exercise}{10} Sea $G=\mathsf{GL}(n,\R)$. Recordemos que podemos identificar $T_IG$
con $\mathsf{M}_n(\R)$. 
\begin{itemize}[listparindent = \parindent]
\item[a)] Para cada $A\in \mathsf{M}_n(\R)$, describa explícitamente el campo tangente
$X_A$ sobre $G$ que es invariante a izquierda y tal que $(X_A)_I=A$.
\item[b)] Determine la funci\'on $\exp:T_eG\to G$.
\item[c)] Muestre que $\exp:T_eG\to G$ no es un homomorfismo de grupos.
\end{itemize}
\end{exercise}
\begin{proof} Hacemos cada inciso por separado.
\begin{itemize}[listparindent = \parindent]
\item[a)] Fijemos $A \in \mathsf{M}_n\R$. Sabemos en general que si $G$ es un grupo de Lie, el campo tangente $X_v \in \mathfrak{X}(G)$ invariante a izquierda que vale $v \in T_eG$ en la identidad es
\begin{align}
(X_v)_g = (L_g)_{\ast,e}(v).
\end{align}
En este caso la multiplicaci\'on est\'a dada por la multiplicaci\'on matricial, y tenemos una identifiaci\'on $T_B\mathsf{M}_n\R \equiv \mathsf{M}_n\R$ para toda matriz $B$ al ser $\mathsf{M}_n\R$ un $\R$-espacio vectorial. 

Como la multiplicaci\'on a izquierda por una matriz fija es $\R$-lineal, bajo estas identificaciones es $(L_B)_{\ast,I}(C) = L_B(C) = BC$ para todo par de matrices $B,C \in \mathsf{M}_n\R$. 

Consecuentemente $\paint{(1)}$ nos dice que
\begin{align*}
(X_A)_B = (L_B)_{\ast,I}(A) = BA
\end{align*}
para cada $B \in \mathsf{M}_n\R$.
\item[b)] Determinemos ahora $\exp: T_I\mathsf{M}_n\R \to \mathsf{M}_n\R$. Dada $A \in \mathsf{M}_n\R$, bajo las identifiaciones de $\paint{(a)}$ la curva integral $\gamma$ de $X_A$ que comienza en $I$ debe satisfacer la ecuaci\'on diferencial con datos iniciales dada por
\begin{align}
\begin{cases}
\gamma'(t) = (X_A)_{\gamma(t)} = \gamma(t)A\\
\gamma(0) = I
\end{cases}
\end{align}
La soluci\'on a \'esta \'ultima es conocida, y es precisamente la curva
\begin{align*}
e^{tA} := \sum_{k \geq 0}\frac{(tA)^k}{k!}.
\end{align*}
En efecto, notemos que esta serie es absolutamente covergente para todo $t \in \R$ ya que
\begin{align*}
\sum_{k \geq 0}\left\|\frac{(tA^k)}{k!}\right\| = \sum_{k \geq 0}\frac{t^k}{k!}\|A^k\| \leq \sum_{k \geq 0}\frac{t^k}{k!}\|A\|^k = \sum_{k \geq 0}\frac{(\|A\|t)^k}{k!} = e^{t\|A\|} < + \infty.
\end{align*}
Por lo tanto podemos derivar t\'ermino a t\'ermino,
\begin{align*}
\frac{d}{dt}e^{tA} &= \sum_{k \geq 0}\frac{d}{dt}\frac{(tA)^k}{k!} = \sum_{k \geq 0}\frac{d}{dt}\frac{t^kA^k}{k!} = \sum_{k \geq 1}\frac{kt^{k-1}A^k}{k!}\\ 
&= \sum_{k \geq 1}\frac{(tA)^{k-1}}{(k-1)!} \cdot A = \sum_{k \geq 0}\frac{(tA)^{k}}{k!} \cdot A = e^{tA} \cdot A.
\end{align*}
Es claro adem\'as que $e^{0 \cdot A} = I + \sum_{k \geq 1}\frac{0^k}{k!} = I$. En conclusi\'on, identificando $T_I\mathsf{M}_n\R$ con $\mathsf{M}_n\R$ obtenemos $\exp(A) = e^A$ para toda $A \in \mathsf{M}_n\R$.
\item[c)] Consideremos las siguientes matrices nilpotentes de $\mathsf{M}_2\R$,
\begin{align*}
A = \begin{pmatrix}
0 & 1\\
0 & 0
\end{pmatrix}, \ B = \begin{pmatrix}
0 & 0\\
1 & 0
\end{pmatrix}.
\end{align*}

Como $A^2 = B^2 = 0$, por un c\'alculo directo, es
\begin{align*}
\exp(A) = I + A = \begin{pmatrix}
1 & 1\\
0 & 1
\end{pmatrix} \text{ y } \exp(B) = I + B = \begin{pmatrix}
1 & 0\\
1 & 1
\end{pmatrix}
\end{align*}
as\'i que 
\begin{align*}
\exp(A)\exp(B) = \begin{pmatrix}
1 & 1\\
0 & 1
\end{pmatrix} \cdot \begin{pmatrix}
1 & 0\\
1 & 1
\end{pmatrix} = \begin{pmatrix}
2 & 1\\
1 & 1
\end{pmatrix}.
\end{align*}

Sin embargo, como $(A+B)^2 = \begin{pmatrix}
0 & 1\\
1 & 0
\end{pmatrix}^2 = I$, es
\begin{align*}
\exp(A+B) &= \sum_{k \geq 0}\frac{(A+B)^k}{k!} = \sum_{k \geq 0}\frac{(A+B)^{2k}}{(2k)!} + \sum_{k \geq 0}\frac{(A+B)^{2k+1}}{(2k+1)!}\\
&= \sum_{k \geq 0}\frac{I}{(2k)!} + \sum_{k \geq 0}\frac{A+B}{(2k+1)!}
\end{align*}
y usando que las proyecciones a cada coordenada son continuas, vemos que
\begin{align*}
\pi_{21}(\exp(A+B)) = \sum_{k \geq 0}\frac{1}{(2k)!} + \sum_{k \geq 0}\frac{1}{(2k+1)!} = e.
\end{align*}
Esto nos dice que $\exp(A+B)_{21} \neq (\exp(A)\exp(B))_{21}$ y por lo tanto $\exp(A+B) \neq \exp(A)\exp(B)$, lo que muestra que $\exp$ no es un morfismo de grupos.
\end{itemize}
\end{proof}

\end{document}
